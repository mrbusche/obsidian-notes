through 3 chapters

Many repetitive problems today have been difficult to automate or support with reliable software tools. Existing research suggest that some of the automation challenges arise because these tasks require _tacit knowledge_— a form of knowledge that is challenging to articulate or codify but more readily transferred through experience or practice. However, groups of agents enabled by LLMs that encode vast amounts of knowledge and can collaborate with humans and other agents provide a new opportunity to address these complex tasks. This approach can help to automate tasks that were previously considered infeasible to automate, thus reducing human effort and potentially errors.

**On Adaptability, Autonomy and Human Oversight**
It is important to emphasize that adaptability and autonomy within multi-agent systems is not intended to replace human participation but to complement it. This ensures that critical oversight and decision-making remain firmly in human hands, especially for managing safety and quality. Such an approach allows humans to strategically intervene or delegate tasks, thus reducing repetitive and labor-intensive work. This concept mirrors the balance found in aviation control systems, where the interplay between autonomy and human oversight is critical for safety and efficiency. Finally, while the core reasoning capabilities of LLMs that drive agents are constantly improving, there is always the potential for agents to arrive at suboptimal, inefficient or incorrect solutions. In such cases, human oversight is crucial to ensure that the agents are on the right path and to correct any errors that may arise.

## Components of a Multi-Agent System
The core components of a multi-agent system can be categorized into two high-level concepts: **agent capabilities** and **agent interactions**. Agent capabilities refer to the methods by which agents address tasks, including mechanisms for reasoning (planning, deducing, etc.), acting (utilizing tools), and adapting (learning, recalling information from memory). On the other hand, agent interactions pertain to how agents communicate and collaborate to solve tasks. This includes agent workflows (how agents are organized or grouped to address tasks) and agent orchestration (the sequence in which agents take action as the task progresses). Importantly, agent capabilities and interactions can be driven by a combination of generative AI models, tools, and human input. For example, an agent may use a generative AI model to reason over a task, execute code to act on the task, and communicate with other agents to collaborate on the task. Similarly, agent orchestration may be driven by a generative AI model that reasons over the state of the task and the capabilities of the agents to determine the next steps in the task, determined by some deterministic orchestration tool, or explicitly driven by human input. Figure [1.4](https://livebook.manning.com/book/multi-agent-systems-with-autogen/chapter-1/v-2/72#ch1-figure-components) provides an overview of these components and their relationships.

AutoGen is an open source framework designed to bridge this gap and offers a flexible API for building multi-agent systems powered by generative AI models.


When to and when not to use a Multi-Agent approach

1. **Is the task complex, and does it involve multiple steps or sub-tasks?** If the task can be decomposed into smaller, interconnected tasks or steps, a multi-agent approach could offer a more modular and flexible solution that can leverage the diverse capabilities of individual agents. Example: Building a personalized travel itinerary involves multiple sub-tasks like booking flights, finding accommodation, suggesting activities, and managing budgets. Each sub-task could be handled by specialized agents (Flight Booking Agent, Hotel Finder Agent, etc.) that collaborate to create the final itinerary.
2. **Does the task require diverse expertise or specialized knowledge?** Multi-agent systems excel in situations where different agents can bring specific expertise to the table. If the task involves various areas of knowledge or specialized skills, a multi-agent approach may be more effective than a single-agent system. Example: Developing a financial trading strategy might require input from agents specializing in market analysis (Market Data Agent), risk assessment (Risk Management Agent), and portfolio optimization (Portfolio Optimization Agent).
3. **Do task requirements or the environment change dynamically, necessitating adaptive solutions?** Multi-agent systems can provide flexibility and adaptability in response to changes in task requirements or the environment. If your task occurs in a dynamic setting where system adaptation is valuable, or the ability to explore multiple approaches, retry and learn can improve performance with an acceptable tradeoff, a multi-agent approach may be a suitable option. Example: Managing a smart home requires agents to adapt to changing conditions (temperature, time of day, user presence, weather forcasts) and _planning_ a set of actions that are appropriate (e.g., adjusting thermostat settings, turning lights on/off, managing security systems).
4. **Is the task context-heavy with a need to process a large amount of information?** Multi-agent systems can handle extensive context because agents can selectively share and manage context with one another. If your task involves working with, managing, or processing large amounts of context, a multi-agent approach may be beneficial. Example: Providing customer service in a technical support scenario requires agents to process previous interactions, user history, product documentation, and knowledge base articles to offer accurate solutions. A multi-agent system could efficiently manage and share this context among specialized agents.
5. **Is the task repetitive, effortful, and tedious yet challenging to automate?** Multi-agent systems can alleviate human effort by providing automation for tasks that rely on tacit knowledge, which can be challenging to codify and automate. If the task is commonly performed by humans but is effortful and tedious, multi-agent systems can significantly ease the burden. Example: Reviewing legal documents for specific clauses or inconsistencies can be tedious and time-consuming for humans. A multi-agent system could use specialized agents (Document Parsing Agent, Clause Detection Agent) to automate this process, freeing up human lawyers for more strategic tasks.

Implementing core agent capabilities can be challenging. AutoGen is an open source framework that addresses this challenge by providing a flexible API for building multi-agent applications powered by generative AI models. AutoGen implements a conversational programming paradigm, supports autonomous workflows, human input mode support, and a code-first approach to agent action.

An agent might have access to multiple tools, thus we need some mechanism to correctly represent available tool specifications to agents such that the right tool can be selected for a given task. An emerging pattern in this area is to use an LLM to both select the appropriate tool, and extract the right parameters for calling the tool.

The capability of reliably translating natural language requests into structured parameters for prescribed functions is known as _function calling_ or _tool calling_

For example we may save the `generate_and_save_images` function to a file named `tools.py` and update the system message for the `AssistantAgent` to include a section on using the `generate_and_save_images` function to generate images e.g., "When you need to generate images, import the `generate_and_save_images` function from the `tools.py` file and call it with the appropriate arguments." This approach offers some flexibility as the LLM has more context on the structure of the function and if needed can generate an updated version of the function as part of its response that subsequently can be executed by the `UserProxyAgent`

Agents must handle interruptions gracefully, allowing users to pause, resume, or cancel actions based on changing requirements or new input. Multi-agent systems are most applicable to tasks that are complex - require planning across multiple steps, and may take time to complete. In such scenarios, users may need to interrupt the agent to provide additional information, correct mistakes, or change the task’s direction. The absence of interruptibility can lead to user frustration and a lack of trust in the system.

The evolution of software development practices from traditional software development to autonomous multi-agent systems has shifted the focus from explicit code writing to defining agents that realize dynamic, adaptive, and intelligent systems. Rather than simply write rules to solve tasks, developers of multi-agent systems must now define agent capabilities and orchestrating mechanisms that enable them to address a vast array of tasks.